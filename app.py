""
import streamlit as st
from textblob import TextBlob
import matplotlib.pyplot as plt
import pandas as pd
import datetime
import time
import os
from wordcloud import WordCloud
from fpdf import FPDF  # fpdf2 is backward compatible, this line stays the same
import io
import openai

# -----------------------------------
# Setup - Ensure data folder exists
# -----------------------------------
os.makedirs("data", exist_ok=True)

st.set_page_config(page_title="Insurance Sentiment Dashboard", layout="wide")

# -----------------------------------
# Upload UI
# -----------------------------------
st.title("Insurance Sentiment Dashboard")

# Sidebar for upload and filters
with st.sidebar:
    st.header("Upload & Filters")
    uploaded_file = st.file_uploader("Upload Processed CSV File", type="csv")
    search_keyword = st.text_input("Search Keyword in Posts:")
    openai_api_key = st.text_input("Enter OpenAI API Key:", type="password")

# Sentiment Analysis Helper
def analyze_sentiment(text):
    analysis = TextBlob(str(text))
    polarity = analysis.sentiment.polarity
    if polarity > 0.1:
        return "positive", polarity
    elif polarity < -0.1:
        return "negative", polarity
    else:
        return "neutral", polarity

# PDF Report Generator
def generate_pdf_report(total_posts, negative_pct, avg_polarity, date_range):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)

    pdf.cell(200, 10, txt="Insurance Sentiment Report", ln=True, align='C')
    pdf.ln(10)

    pdf.cell(200, 10, txt=f"Total Posts Analysed: {total_posts}", ln=True)
    pdf.cell(200, 10, txt=f"% Negative Sentiment: {negative_pct:.1f}%", ln=True)
    pdf.cell(200, 10, txt=f"Average Sentiment Polarity: {avg_polarity:.2f}", ln=True)
    pdf.cell(200, 10, txt=f"Date Range: {date_range}", ln=True)

    pdf.ln(10)
    pdf.cell(200, 10, txt="Generated by Insurance Sentiment Dashboard", ln=True)

    pdf_output = io.BytesIO()
    pdf.output(pdf_output)
    pdf_output.seek(0)
    return pdf_output

# GPT-4 Chatbot Insight Function
def query_gpt_insights(df, query, api_key):
    openai.api_key = api_key

    # Prepare context with sample data
    context = df[['text', 'sentiment', 'platform', 'factor', 'created_at']].head(10).to_string(index=False)

    prompt = f"""
You are a data analyst. A user uploaded social media data related to insurance. Here are sample rows:
{context}

Now answer the following question based on overall patterns in the full dataset:
{query}
"""
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a helpful insurance data analyst."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
            max_tokens=300
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        return f"Error: {str(e)}"

# -----------------------------------
# Dashboard Logic
# -----------------------------------
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)

    if "text" not in df.columns:
        st.error("CSV must contain a 'text' column.")
        st.stop()

    if "created_at" not in df.columns:
        df["created_at"] = datetime.datetime.now().isoformat()

    # Analyse if not already done
    if "sentiment" not in df.columns or "polarity" not in df.columns:
        sentiments, polarities = [], []
        for t in df["text"]:
            sentiment, polarity = analyze_sentiment(t)
            sentiments.append(sentiment)
            polarities.append(polarity)
        df["sentiment"] = sentiments
        df["polarity"] = polarities

    df['created_at'] = pd.to_datetime(df['created_at'])
    df['date'] = df['created_at'].dt.date

    # Filters: Platform and Factor
    platforms = df['platform'].unique().tolist() if 'platform' in df.columns else []
    factors = df['factor'].unique().tolist() if 'factor' in df.columns else []

    selected_platforms = st.sidebar.multiselect("Select Platforms:", platforms, default=platforms)
    selected_factors = st.sidebar.multiselect("Select Service Factors:", factors, default=factors)

    if platforms:
        df = df[df['platform'].isin(selected_platforms)]
    if factors:
        df = df[df['factor'].isin(selected_factors)]

    if search_keyword:
        df = df[df['text'].str.contains(search_keyword, case=False, na=False)]

    # Tabs for Dashboard Sections
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìä KPIs", "üìà Charts", "üìù Negative Posts", "‚òÅÔ∏è Word Cloud", "ü§ñ Insights Bot"])

    with tab1:
        st.subheader("Key Performance Indicators (KPIs)")
        total_posts = len(df)
        negative_pct = (len(df[df['sentiment'] == 'negative']) / total_posts) * 100 if total_posts > 0 else 0
        avg_polarity = df['polarity'].mean() if total_posts > 0 else 0
        date_range = f"{df['date'].min()} to {df['date'].max()}" if total_posts > 0 else "N/A"

        last_week = datetime.date.today() - datetime.timedelta(days=7)
        prev_week_df = df[df['date'] < last_week]
        curr_week_df = df[df['date'] >= last_week]

        prev_negative_pct = (len(prev_week_df[prev_week_df['sentiment'] == 'negative']) / len(prev_week_df) * 100) if len(prev_week_df) > 0 else 0
        delta_negative = negative_pct - prev_negative_pct

        kpi1, kpi2, kpi3, kpi4 = st.columns(4)
        kpi1.metric(label="Total Posts Analysed", value=total_posts)
        kpi2.metric(label="% Negative Sentiment", value=f"{negative_pct:.1f}%", delta=f"{delta_negative:.1f}%")
        kpi3.metric(label="Average Polarity", value=f"{avg_polarity:.2f}")
        kpi4.metric(label="Date Range", value=date_range)

        if negative_pct > 30:
            st.warning(f"‚ö†Ô∏è Alert: Negative sentiment is high at {negative_pct:.1f}%")

        if 'platform' in df.columns:
            st.markdown("---")
            st.subheader("Posts by Platform")
            platform_counts = df['platform'].value_counts()
            st.bar_chart(platform_counts)

        if 'factor' in df.columns:
            st.markdown("---")
            st.subheader("Posts by Service Factor")
            factor_counts = df['factor'].value_counts()
            st.bar_chart(factor_counts)

        # Export Button
        st.download_button(
            label="Download Filtered Data as CSV",
            data=df.to_csv(index=False).encode('utf-8'),
            file_name="filtered_sentiment_data.csv",
            mime="text/csv"
        )

        # PDF Report Button
        pdf_file = generate_pdf_report(total_posts, negative_pct, avg_polarity, date_range)
        st.download_button(
            label="Download PDF Report",
            data=pdf_file,
            file_name="sentiment_report.pdf",
            mime="application/pdf"
        )

    with tab2:
        st.subheader("Sentiment Breakdown")
        sentiment_counts = df['sentiment'].value_counts().to_dict()
        labels = list(sentiment_counts.keys())
        sizes = list(sentiment_counts.values())
        colors = ['#66b3ff', '#ffcc99', '#ff9999']
        fig1, ax1 = plt.subplots(figsize=(5,5))
        ax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, colors=colors)
        ax1.axis('equal')
        st.pyplot(fig1)

        st.subheader("Sentiment Over Time")
        sentiment_time = df.groupby(['date', 'sentiment']).size().unstack(fill_value=0)
        st.line_chart(sentiment_time)

    with tab3:
        st.subheader("Top 5 Most Negative Posts")
        top_neg = df[df['sentiment'] == 'negative'].sort_values(by='polarity').head
